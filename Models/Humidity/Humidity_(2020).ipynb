{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Shanaka-PC\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Shanaka-PC\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Shanaka-PC\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Shanaka-PC\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Shanaka-PC\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Shanaka-PC\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Shanaka-PC\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Shanaka-PC\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Shanaka-PC\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Shanaka-PC\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Shanaka-PC\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Shanaka-PC\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Colo - Temp.csv', 'Colo-Humidity.csv', 'New folder', 'precentage error calcuate.png', 'PredictedTemp.csv', 'PredictedTemp2019.csv', 'Temperature_(2020).html', 'Temperature_(2020).ipynb', 'Temp_(2020)', 'Temp_(2020).h5']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import pprint\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\")) #loading all the files on input folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('../input/Colo-Humidity.csv') #adding 'Colo-Humidity' csv to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2009</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/1/2009</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/1/2009</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/1/2009</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/1/2009</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>27/12/2019</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4013</th>\n",
       "      <td>28/12/2019</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4014</th>\n",
       "      <td>29/12/2019</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4015</th>\n",
       "      <td>30/12/2019</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>31/12/2019</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4017 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date  Humidity\n",
       "0        1/1/2009        62\n",
       "1        2/1/2009        59\n",
       "2        3/1/2009        58\n",
       "3        4/1/2009        66\n",
       "4        5/1/2009        68\n",
       "...           ...       ...\n",
       "4012  27/12/2019         77\n",
       "4013  28/12/2019         78\n",
       "4014  29/12/2019         76\n",
       "4015  30/12/2019         78\n",
       "4016  31/12/2019         81\n",
       "\n",
       "[4017 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe #displaying the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.Date=pd.to_datetime(dataframe.Date)\n",
    "dataframe=dataframe.set_index('Date') #setting the index by the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-02-01</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-03-01</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-01</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-01</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4017 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Humidity\n",
       "Date                \n",
       "2009-01-01        62\n",
       "2009-02-01        59\n",
       "2009-03-01        58\n",
       "2009-04-01        66\n",
       "2009-05-01        68\n",
       "...              ...\n",
       "2019-12-27        77\n",
       "2019-12-28        78\n",
       "2019-12-29        76\n",
       "2019-12-30        78\n",
       "2019-12-31        81\n",
       "\n",
       "[4017 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe #displaying the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData = dataframe.tail(365) #setting the testing set as the last year of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DfTotal = pd.concat((dataframe[[\"Humidity\"]], TestData[[\"Humidity\"]]), axis=0) #concating the dataset with the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4382, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DfTotal.shape #getting the shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(425, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = DfTotal[len(DfTotal) - len(TestData) - 60:].values\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating new dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import DateOffset\n",
    "AddDates = [dataframe.index[-1] + DateOffset(days=x) for x in range(0,366)]\n",
    "FutureDates = pd.DataFrame(index=AddDates[1:],columns=dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-26</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-27</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Humidity\n",
       "2020-01-01      NaN\n",
       "2020-01-02      NaN\n",
       "2020-01-03      NaN\n",
       "2020-01-04      NaN\n",
       "2020-01-05      NaN\n",
       "...             ...\n",
       "2020-12-26      NaN\n",
       "2020-12-27      NaN\n",
       "2020-12-28      NaN\n",
       "2020-12-29      NaN\n",
       "2020-12-30      NaN\n",
       "\n",
       "[365 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FutureDates.tail(365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4017, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingSet = dataframe #passing the full dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingSet = TrainingSet.values\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "Train = sc.fit_transform(TrainingSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Setting Min Max Scaler with the default feature range to the training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4017, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3957, 60, 1)\n",
      "(3957, 1)\n"
     ]
    }
   ],
   "source": [
    "X_Train = []\n",
    "Y_Train = []\n",
    "\n",
    "for i in range(60, Train.shape[0]): # Range should be from 60 Values to END\n",
    "   \n",
    "    X_Train.append(Train[i-60:i]) # X_Train 0-59\n",
    "   \n",
    "    Y_Train.append(Train[i]) # Y Would be 60 th Value based on past 60 Values\n",
    "\n",
    "# Convert into Numpy Array\n",
    "X_Train = np.array(X_Train)\n",
    "Y_Train = np.array(Y_Train)\n",
    "\n",
    "print(X_Train.shape)\n",
    "print(Y_Train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3957, 60, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train = np.reshape(X_Train, newshape=(X_Train.shape[0], X_Train.shape[1], 1))\n",
    "X_Train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "XploreReg = Sequential()\n",
    "\n",
    "# Adding first LSTM layer with Dropout \n",
    "XploreReg.add(LSTM(units = 150, return_sequences = True,input_shape = (X_Train.shape[1], 1)))\n",
    "XploreReg.add(Dropout(0.2))\n",
    "\n",
    "# Adding second LSTM layer with Dropout\n",
    "XploreReg.add(LSTM(units = 150, return_sequences = True))\n",
    "XploreReg.add(Dropout(0.2))\n",
    "\n",
    "# Adding third LSTM layer with Dropout\n",
    "XploreReg.add(LSTM(units = 150, return_sequences = True))\n",
    "XploreReg.add(Dropout(0.2))\n",
    "\n",
    "# Adding fourth LSTM layer with Dropout\n",
    "XploreReg.add(LSTM(units = 150))\n",
    "XploreReg.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "XploreReg.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 60, 150)           91200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 150)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 60, 150)           180600    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60, 150)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 60, 150)           180600    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 60, 150)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 150)               180600    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 633,151\n",
      "Trainable params: 633,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "XploreReg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shanaka-PC\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "3957/3957 [==============================] - 94s 24ms/step - loss: 0.0185\n",
      "Epoch 2/100\n",
      "3957/3957 [==============================] - 105s 26ms/step - loss: 0.0127\n",
      "Epoch 3/100\n",
      "3957/3957 [==============================] - 117s 30ms/step - loss: 0.0102\n",
      "Epoch 4/100\n",
      "3957/3957 [==============================] - 120s 30ms/step - loss: 0.0083\n",
      "Epoch 5/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0078\n",
      "Epoch 6/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0072\n",
      "Epoch 7/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0072\n",
      "Epoch 8/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0070\n",
      "Epoch 9/100\n",
      "3957/3957 [==============================] - 107s 27ms/step - loss: 0.0072\n",
      "Epoch 10/100\n",
      "3957/3957 [==============================] - 107s 27ms/step - loss: 0.0070\n",
      "Epoch 11/100\n",
      "3957/3957 [==============================] - 115s 29ms/step - loss: 0.0068\n",
      "Epoch 12/100\n",
      "3957/3957 [==============================] - 107s 27ms/step - loss: 0.0067\n",
      "Epoch 13/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0066\n",
      "Epoch 14/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0068\n",
      "Epoch 15/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0066\n",
      "Epoch 16/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0066\n",
      "Epoch 17/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0067\n",
      "Epoch 18/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0063\n",
      "Epoch 19/100\n",
      "3957/3957 [==============================] - 107s 27ms/step - loss: 0.0064\n",
      "Epoch 20/100\n",
      "3957/3957 [==============================] - 107s 27ms/step - loss: 0.0063\n",
      "Epoch 21/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0064\n",
      "Epoch 22/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0063\n",
      "Epoch 23/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0064\n",
      "Epoch 24/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0063\n",
      "Epoch 25/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0062\n",
      "Epoch 26/100\n",
      "3957/3957 [==============================] - 107s 27ms/step - loss: 0.0062\n",
      "Epoch 27/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0062\n",
      "Epoch 28/100\n",
      "3957/3957 [==============================] - 107s 27ms/step - loss: 0.0062\n",
      "Epoch 29/100\n",
      "3957/3957 [==============================] - 110s 28ms/step - loss: 0.0062\n",
      "Epoch 30/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0061\n",
      "Epoch 31/100\n",
      "3957/3957 [==============================] - 107s 27ms/step - loss: 0.0062\n",
      "Epoch 32/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0061\n",
      "Epoch 33/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0061\n",
      "Epoch 34/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0062\n",
      "Epoch 35/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0061\n",
      "Epoch 36/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0060\n",
      "Epoch 37/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0061\n",
      "Epoch 38/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0061\n",
      "Epoch 39/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0060\n",
      "Epoch 40/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0060\n",
      "Epoch 41/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0060\n",
      "Epoch 42/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0060\n",
      "Epoch 43/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0060\n",
      "Epoch 44/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0060\n",
      "Epoch 45/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0058\n",
      "Epoch 46/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0058\n",
      "Epoch 47/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0059\n",
      "Epoch 48/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0059\n",
      "Epoch 49/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0059\n",
      "Epoch 50/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0058\n",
      "Epoch 51/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0059\n",
      "Epoch 52/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0059\n",
      "Epoch 53/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0060\n",
      "Epoch 54/100\n",
      "3957/3957 [==============================] - 107s 27ms/step - loss: 0.0058\n",
      "Epoch 55/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0058\n",
      "Epoch 56/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0059\n",
      "Epoch 57/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0057\n",
      "Epoch 58/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0059\n",
      "Epoch 59/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0058\n",
      "Epoch 60/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0058\n",
      "Epoch 61/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0057\n",
      "Epoch 62/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0057\n",
      "Epoch 63/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0056\n",
      "Epoch 64/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0057\n",
      "Epoch 65/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0057\n",
      "Epoch 66/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0057\n",
      "Epoch 67/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0057\n",
      "Epoch 68/100\n",
      "3957/3957 [==============================] - 107s 27ms/step - loss: 0.0057\n",
      "Epoch 69/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0056\n",
      "Epoch 70/100\n",
      "3957/3957 [==============================] - 109s 27ms/step - loss: 0.0057\n",
      "Epoch 71/100\n",
      "3957/3957 [==============================] - 107s 27ms/step - loss: 0.0056\n",
      "Epoch 72/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0056\n",
      "Epoch 73/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0055\n",
      "Epoch 74/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0056\n",
      "Epoch 75/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0055\n",
      "Epoch 76/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0055\n",
      "Epoch 77/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0056\n",
      "Epoch 78/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0056\n",
      "Epoch 79/100\n",
      "3957/3957 [==============================] - 109s 28ms/step - loss: 0.0055\n",
      "Epoch 80/100\n",
      "3957/3957 [==============================] - 126s 32ms/step - loss: 0.0056\n",
      "Epoch 81/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0055\n",
      "Epoch 82/100\n",
      "3957/3957 [==============================] - 107s 27ms/step - loss: 0.0054\n",
      "Epoch 83/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0055\n",
      "Epoch 84/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0054\n",
      "Epoch 85/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0056\n",
      "Epoch 86/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0053\n",
      "Epoch 87/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.00531s - \n",
      "Epoch 88/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0054\n",
      "Epoch 89/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0053\n",
      "Epoch 90/100\n",
      "3957/3957 [==============================] - 107s 27ms/step - loss: 0.0052\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0053\n",
      "Epoch 92/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0052\n",
      "Epoch 93/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0053\n",
      "Epoch 94/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0052\n",
      "Epoch 95/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0051\n",
      "Epoch 96/100\n",
      "3957/3957 [==============================] - 107s 27ms/step - loss: 0.0052\n",
      "Epoch 97/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0051\n",
      "Epoch 98/100\n",
      "3957/3957 [==============================] - 105s 27ms/step - loss: 0.0051\n",
      "Epoch 99/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0051\n",
      "Epoch 100/100\n",
      "3957/3957 [==============================] - 106s 27ms/step - loss: 0.0050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x233ef7d0a88>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XploreReg.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "XploreReg.fit(X_Train,Y_Train, epochs = 100, batch_size = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per Epoch Time for CPU based \n",
    "1. i5 8th gen laptop = 250s/4mins\n",
    "2. i7 8th gen laptop = 150s/2.5mins\n",
    "3. i3 8th gen laptop = 110s/1min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FutureDates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = DfTotal[len(DfTotal) - len(TestData) - 60:].values\n",
    "\n",
    "# We need to Reshape\n",
    "inputs = inputs.reshape(-1,1)\n",
    "\n",
    "# Normalize the Dataset\n",
    "inputs = sc.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "for i in range(60, 425):\n",
    "    X_test.append(inputs[i-60:i])\n",
    "       \n",
    "# Convert into Numpy Array\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Reshape before Passing to Network\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Pass to Model\n",
    "predicted_Humid = XploreReg.predict(X_test)\n",
    "\n",
    "# Do inverse Transformation to get Values\n",
    "predicted_Humid = sc.inverse_transform(predicted_Humid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_Humid = 0\n",
    "Predicted_Humid  = predicted_Humid\n",
    "dates = TestData.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted_Df = pd.DataFrame(data={\n",
    "    \"Date\":FutureDates.index.to_list(),\n",
    "    \"TrueHumidity\": True_Humid,\n",
    "    \"PredictedHumidity\":[x[0] for x in predicted_Humid]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>TrueHumidity</th>\n",
       "      <th>PredictedHumidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>80.027321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>76.054855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>75.042053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>74.646797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>75.091187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2020-12-26</td>\n",
       "      <td>0</td>\n",
       "      <td>80.694260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>0</td>\n",
       "      <td>77.007370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>0</td>\n",
       "      <td>79.322449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>0</td>\n",
       "      <td>77.041809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>0</td>\n",
       "      <td>78.987213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  TrueHumidity  PredictedHumidity\n",
       "0   2020-01-01             0          80.027321\n",
       "1   2020-01-02             0          76.054855\n",
       "2   2020-01-03             0          75.042053\n",
       "3   2020-01-04             0          74.646797\n",
       "4   2020-01-05             0          75.091187\n",
       "..         ...           ...                ...\n",
       "360 2020-12-26             0          80.694260\n",
       "361 2020-12-27             0          77.007370\n",
       "362 2020-12-28             0          79.322449\n",
       "363 2020-12-29             0          77.041809\n",
       "364 2020-12-30             0          78.987213\n",
       "\n",
       "[365 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predicted_Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted_Df.to_csv(\"../input/Humidity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "XploreReg.save('../input/Humidity_(2020)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "XploreReg.save('../input/Humidity_(2020).h5') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
